# -*- coding: utf-8 -*-
"""BlackHoleAccretion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EnJl4fEvhbiMCF0rbj8NaeihVwcqcBvT
"""

import numpy as np
import matplotlib.pyplot as plt
from numba import njit, prange
import time

# ==========================================
# 1. PHYSICAL CONSTANTS & CONFIGURATION
# ==========================================

# Simulation Parameters
WIDTH = 800         # Image width
HEIGHT = 600        # Image height
FOV = 60.0          # Field of view in degrees
STEP_SIZE = 0.05    # Integration step size (dt) for the light ray
MAX_STEPS = 5000    # Maximum steps before we assume the ray escaped
RS = 1.0            # Schwarzschild Radius (Event Horizon radius)

# Derived radii for visualization
R_PHOTON = 1.5 * RS # Photon sphere (light orbit radius)
R_ISCO = 3.0 * RS   # Innermost Stable Circular Orbit (accretion disk start)
R_DISK_MAX = 12.0 * RS # Outer edge of accretion disk

# Camera Setup
CAM_DIST = 30.0     # Distance from Black Hole (Increased to see full disk)
CAM_PITCH = 25.0    # Angle above the accretion disk plane (degrees)

# ==========================================
# 2. NUMBA-ACCELERATED RAY TRACER
# ==========================================

@njit
def get_derivatives(state):
    """
    Calculates the derivatives for the Schwarzschild geodesic equations.
    State vector: [r, r_dot, phi, phi_dot]
    Returns: [r_dot, r_ddot, phi_dot, phi_ddot]
    """
    r = state[0]
    r_dot = state[1]
    phi = state[2]
    phi_dot = state[3]

    # Geodesic Equations for a photon in Schwarzschild metric
    # d^2phi/dlambda^2 = - (2/r) * (dr/dlambda) * (dphi/dlambda)
    phi_ddot = -2.0 / r * r_dot * phi_dot

    # d^2r/dlambda^2 = r * (dphi/dlambda)^2 * (1 - 1.5 * Rs / r)
    r_ddot = r * (phi_dot ** 2) * (1.0 - (1.5 * RS) / r)

    return np.array([r_dot, r_ddot, phi_dot, phi_ddot])

@njit
def rk4_step(state, h):
    """
    Performs a single Runge-Kutta 4 integration step.
    """
    k1 = get_derivatives(state)
    k2 = get_derivatives(state + 0.5 * h * k1)
    k3 = get_derivatives(state + 0.5 * h * k2)
    k4 = get_derivatives(state + h * k3)

    return state + (h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)

@njit
def texture_lookup(r, phi, x_hit, y_hit, z_hit):
    """
    Generates a procedural color for the accretion disk.
    """
    # SMOOTHER RING PATTERN (Reduced high-frequency noise)
    # This creates distinct but smooth concentric rings
    ring_noise = 0.6 * np.sin(r * 2.0) + 0.4 * np.sin(r * 5.0)

    brightness = 0.6 + 0.4 * ring_noise

    # Doppler beaming effect approximation (brighter on approaching side)
    # The disk rotates; assume counter-clockwise.
    # LHS of image is approaching (Blue/Bright), RHS is receding (Red/Dim)
    doppler = 1.0 + 0.5 * (x_hit / r)

    # Color blending: Hot orange to dark red based on distance from ISCO
    # Hotter (yellower) near the center, Redder at edges
    dist_norm = (r - R_ISCO) / (R_DISK_MAX - R_ISCO)
    dist_norm = max(0.0, min(1.0, dist_norm))

    # Gradient
    col_r = 1.0 * brightness * doppler
    col_g = (0.8 - 0.6 * dist_norm) * brightness * doppler
    col_b = (0.3 - 0.3 * dist_norm) * brightness * doppler

    return np.array([col_r, col_g, col_b])

@njit
def ray_march(ray_origin, ray_dir):
    """
    Traces a single ray backwards from the camera.
    Returns the RGB color.
    """
    # 1. TRANSFORM TO PLANAR COORDINATES
    # The trajectory of a photon in Schwarzschild metric is planar.
    # The plane is defined by the ray origin (assuming 0,0,0 is BH) and ray direction.
    # We construct a basis for this plane.

    # Vector pointing from BH to Ray Origin
    pos = ray_origin
    # Initial Velocity Vector
    vel = ray_dir

    # Angular Momentum Vector L = r x v
    L = np.cross(pos, vel)
    L_norm = np.linalg.norm(L)

    # If L is zero, ray is radial (straight into BH).
    if L_norm < 1e-6:
        return np.array([0.0, 0.0, 0.0]) # Hits BH center

    # Define basis vectors for the plane of motion
    # unit_r (at start)
    r_hat = pos / np.linalg.norm(pos)
    # unit_normal (perpendicular to plane)
    n_hat = L / L_norm
    # unit_phi (perpendicular to r and normal)
    phi_hat = np.cross(n_hat, r_hat)

    # Initial State in Polar Coordinates (r, phi)
    # r = distance
    # phi = 0 at the camera's initial position
    r_init = np.linalg.norm(pos)
    phi_init = 0.0

    # Project 3D velocity into 2D polar velocity
    # v_r = v . r_hat
    # v_phi = (v . phi_hat) / r
    dr_init = np.dot(vel, r_hat)
    dphi_init = np.dot(vel, phi_hat) / r_init

    # State: [r, dr, phi, dphi]
    state = np.array([r_init, dr_init, phi_init, dphi_init])

    # 2. RAY MARCHING LOOP
    for i in range(MAX_STEPS):
        old_r = state[0]
        old_phi = state[2]

        # Perform RK4 Integration
        state = rk4_step(state, STEP_SIZE)

        new_r = state[0]
        new_phi = state[2]

        # --- COLLISION CHECKS ---

        # A. EVENT HORIZON CHECK
        if new_r < RS:
            return np.array([0.0, 0.0, 0.0]) # Black hole shadow

        # B. ESCAPE CHECK
        if new_r > 50.0:
            # Ray escaped to infinity -> Skybox / Starfield
            return np.array([0.02, 0.02, 0.05]) # Deep space blue-black

        # C. ACCRETION DISK CHECK
        # The disk lies on the X-Z plane (y=0 in our world space setup, but we need to be careful with coords).
        # Let's assume the disk is in the global z=0 plane (equatorial).
        # We need to reconstruct the global 3D position to check for plane intersection.

        # Reconstruct 3D position from r, phi
        # The position in the orbital plane is:
        # P_plane = r * (cos(phi)*r_hat_init + sin(phi)*phi_hat_init)
        # However, phi is relative to start.
        # Global Pos = r * (cos(phi) * r_hat + sin(phi) * phi_hat)
        pos_3d_new = new_r * (np.cos(new_phi) * r_hat + np.sin(new_phi) * phi_hat)
        pos_3d_old = old_r * (np.cos(old_phi) * r_hat + np.sin(old_phi) * phi_hat)

        # Check if we crossed the Y=0 plane (assuming Y is 'up' in our scene setup)
        # Note: In the setup below, Camera is at (0, Y, -Z). We define Y as Up.
        # Disk is at Y=0.

        y0 = pos_3d_old[1]
        y1 = pos_3d_new[1]

        if (y0 > 0 and y1 < 0) or (y0 < 0 and y1 > 0):
            # We crossed the plane. Find exact intersection using linear interpolation.
            fraction = abs(y0) / (abs(y0) + abs(y1))
            # Interpolate r and phi (approximate)
            hit_r = old_r + (new_r - old_r) * fraction

            # Check if within disk bounds
            if R_ISCO < hit_r < R_DISK_MAX:
                # Calculate hit coordinates for texturing
                hit_pos = pos_3d_old + (pos_3d_new - pos_3d_old) * fraction
                return texture_lookup(hit_r, 0, hit_pos[0], hit_pos[1], hit_pos[2])

    return np.array([0.0, 0.0, 0.0])

@njit(parallel=True)
def render_image(width, height, cam_pos, cam_target, fov):
    """
    Main render loop. Parallelized with Numba.
    """
    image = np.zeros((height, width, 3))
    aspect_ratio = width / height
    fov_rad = np.radians(fov)
    half_height = np.tan(fov_rad / 2.0)
    half_width = aspect_ratio * half_height

    # Camera Coordinate System
    # Forward vector (w)
    w = (cam_target - cam_pos)
    w = w / np.linalg.norm(w)
    # Up vector guide (0, 1, 0)
    up = np.array([0.0, 1.0, 0.0])
    # Right vector (u)
    u = np.cross(w, up)
    u = u / np.linalg.norm(u)
    # Real Up vector (v)
    v = np.cross(u, w)

    # Loop over pixels
    for y in prange(height):
        for x in prange(width):
            # Normalized Device Coordinates (-1 to 1)
            ndc_x = (x + 0.5) / width * 2.0 - 1.0
            ndc_y = 1.0 - (y + 0.5) / height * 2.0 # Flip Y

            # Ray Direction
            pixel_screen_pos = cam_pos + w + u * (ndc_x * half_width) + v * (ndc_y * half_height)
            ray_dir = pixel_screen_pos - cam_pos
            ray_dir = ray_dir / np.linalg.norm(ray_dir)

            color = ray_march(cam_pos, ray_dir)
            image[y, x] = color

    return image

# ==========================================
# 3. MAIN EXECUTION
# ==========================================

def main():
    print(f"Initializing Black Hole Simulation...")
    print(f"Resolution: {WIDTH}x{HEIGHT}")
    print(f"Metric: Schwarzschild")

    # Define Camera Position (Spherical to Cartesian)
    # Pitching up to look down at the disk
    pitch_rad = np.radians(CAM_PITCH)
    cam_y = CAM_DIST * np.sin(pitch_rad)
    cam_z = -CAM_DIST * np.cos(pitch_rad)
    cam_pos = np.array([0.0, cam_y, cam_z])
    cam_target = np.array([0.0, 0.0, 0.0])

    # Compilation Run (Numba needs to compile the code first, so the first run is slower)
    print("Compiling JIT kernels (this might take a few seconds)...")
    start_time = time.time()
    # Run a tiny test render to trigger compilation
    render_image(10, 10, cam_pos, cam_target, FOV)
    print(f"Compilation finished in {time.time() - start_time:.2f}s")

    # Actual Render
    print("Rendering final image...")
    start_time = time.time()
    img_data = render_image(WIDTH, HEIGHT, cam_pos, cam_target, FOV)
    print(f"Render finished in {time.time() - start_time:.2f}s")

    # Display
    plt.figure(figsize=(10, 8), dpi=100)
    plt.imshow(np.clip(img_data, 0, 1))
    plt.axis('off')
    plt.title("Schwarzschild Black Hole Ray Trace (Python/Numba)")
    plt.savefig('black_hole.jpg', bbox_inches='tight')
    print("Image saved as 'black_hole.jpg'")
    plt.show()

if __name__ == "__main__":
    main()

"""# Task
Generate a video animation of the black hole simulation by following these steps:

1.  **Configure Animation Settings**: Set the resolution to 320x240 to reduce rendering time and define a total of 72 frames for the loop.
2.  **Define Polar Orbit Trajectory**: Calculate a sequence of camera positions that perform a full 360-degree rotation in the Y-Z plane (polar orbit) around the black hole at the existing `CAM_DIST`.
3.  **Render Frames**: Iterate through the calculated positions, using the existing `render_image` function to generate a frame for each step.
4.  **Generate Video**: Collect the rendered frames and use `cv2.VideoWriter` to save them as an MP4 video file named "black_hole_orbit.mp4" (e.g., at 24 fps).
5.  **Verify**: output the path of the generated video file to confirm success.

## Configure Animation Settings

### Subtask:
Define parameters for the animation including resolution, frame count, and output filename.

**Reasoning**:
Define animation parameters including resolution, frame count, FPS, and output filename as specified in the instructions.
"""

import cv2

# Animation Parameters
ANIM_WIDTH = 320
ANIM_HEIGHT = 240
NUM_FRAMES = 240  # Increased to 240 for a slower, 10-second orbit
FPS = 24
OUTPUT_FILENAME = 'black_hole_flyby_slow.mp4'

print(f"Animation Configuration:")
print(f"Resolution: {ANIM_WIDTH}x{ANIM_HEIGHT}")
print(f"Frames: {NUM_FRAMES}")
print(f"FPS: {FPS}")
print(f"Output File: {OUTPUT_FILENAME}")

"""**Reasoning**:
Calculate the camera trajectory for a 360-degree polar orbit, render the frames using the defined resolution, and compile them into an MP4 video file.


"""

import numpy as np
import cv2
import os

# Trajectory and Rendering
print(f"Starting render of {NUM_FRAMES} frames for slow flyby...")
frames = []

# Center of the black hole
target = np.array([0.0, 0.0, 0.0])

for i in range(NUM_FRAMES):
    # Angle for this frame (0 to 2pi)
    theta = (2.0 * np.pi * i) / NUM_FRAMES

    # Polar Orbit: Rotation in Y-Z plane
    # We maintain the distance CAM_DIST
    # y = R * sin(theta)
    # z = -R * cos(theta) (Start at -Z, go Up to +Y, then +Z, then -Y)

    y = CAM_DIST * np.sin(theta)
    z = -CAM_DIST * np.cos(theta)
    x = 0.0

    cam_pos_i = np.array([x, y, z])

    # Render
    # Note: render_image was defined in the previous context
    img_data = render_image(ANIM_WIDTH, ANIM_HEIGHT, cam_pos_i, target, FOV)

    # Convert to uint8
    img_data = np.clip(img_data, 0.0, 1.0)
    img_uint8 = (img_data * 255).astype(np.uint8)

    # RGB to BGR for OpenCV
    frame_bgr = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR)
    frames.append(frame_bgr)

    if (i + 1) % 20 == 0:
        print(f"Rendered {i + 1}/{NUM_FRAMES} frames")

# Save to MP4
print(f"Saving video to {OUTPUT_FILENAME}...")
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_FILENAME, fourcc, FPS, (ANIM_WIDTH, ANIM_HEIGHT))

for frame in frames:
    out.write(frame)

out.release()

if os.path.exists(OUTPUT_FILENAME):
    print(f"Video generated successfully: {os.path.abspath(OUTPUT_FILENAME)}")
else:
    print("Error: Video file was not created.")

"""## Final Task

### Subtask:
Verify the existence and validity of the generated MP4 video file.

## Summary:

### Q&A

**Q:** Was the video animation of the black hole simulation successfully generated?
**A:** Yes, the system successfully rendered the frames and compiled them into a video file named `black_hole_orbit.mp4`, confirming the file's existence at the absolute path `/content/black_hole_orbit.mp4`.

### Data Analysis Key Findings

*   **Animation Configuration:** The rendering parameters were set to a resolution of **320x240** with a total of **72 frames** running at **24 FPS** to ensure a balance between visual feedback and processing time.
*   **Trajectory Calculation:** A polar orbit trajectory was successfully calculated, mapping camera positions across a 360-degree rotation in the Y-Z plane while maintaining a constant distance from the black hole.
*   **Rendering and compilation:** All 72 frames were rendered, converted from RGB to BGR format for OpenCV compatibility, and successfully written to the output MP4 file without errors.

### Insights or Next Steps

*   **Quality Scaling:** While the 320x240 resolution allows for rapid prototyping, increasing the resolution (e.g., to 1080p) and the sample count per pixel in future iterations would produce a high-definition visualization of the gravitational lensing effects.
*   **File Utilization:** The generated `black_hole_orbit.mp4` is a 3-second seamless loop; it can now be downloaded or embedded in a presentation to demonstrate the simulation dynamics.

# Task
```python
import numpy as np
import cv2
import os

# Animation Parameters for High-Resolution Inclined Orbit
ANIM_WIDTH = 1000
ANIM_HEIGHT = 750
NUM_FRAMES = 360  # For a smoother 360-degree loop
FPS = 24
OUTPUT_FILENAME = 'black_hole_inclined_orbit.mp4'
INCLINATION_ANGLE_DEG = 45.0 # Angle relative to the equatorial (XZ) plane

print(f"Animation Configuration for Inclined Orbit:")
print(f"Resolution: {ANIM_WIDTH}x{ANIM_HEIGHT}")
print(f"Frames: {NUM_FRAMES}")
print(f"FPS: {FPS}")
print(f"Inclination Angle: {INCLINATION_ANGLE_DEG} degrees")
print(f"Output File: {OUTPUT_FILENAME}")

# Trajectory and Rendering
print(f"\nStarting render of {NUM_FRAMES} frames for inclined orbit...")
frames = []

# Center of the black hole (camera target)
target = np.array([0.0, 0.0, 0.0])

inclination_rad = np.radians(INCLINATION_ANGLE_DEG)

for i in range(NUM_FRAMES):
    # Orbital angle for this frame (0 to 2pi)
    theta = (2.0 * np.pi * i) / NUM_FRAMES

    # Calculate camera position for a 45-degree inclined orbit
    # Assuming Y-axis is 'north-south' and XZ plane is 'equator'.
    # Start with an orbit in the XZ plane (equator) and rotate it around the X-axis
    # by the inclination angle.
    x = CAM_DIST * np.cos(theta)
    y = CAM_DIST * np.sin(theta) * np.sin(inclination_rad)
    z = CAM_DIST * np.sin(theta) * np.cos(inclination_rad)

    cam_pos_i = np.array([x, y, z])

    # Render frame
    # render_image, CAM_DIST, and FOV are defined in previous cells
    img_data = render_image(ANIM_WIDTH, ANIM_HEIGHT, cam_pos_i, target, FOV)

    # Convert to uint8 for OpenCV
    img_data = np.clip(img_data, 0.0, 1.0)
    img_uint8 = (img_data * 255).astype(np.uint8)

    # Convert RGB to BGR for OpenCV
    frame_bgr = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR)
    frames.append(frame_bgr)

    if (i + 1) % (NUM_FRAMES // 10) == 0 or i == 0 or i == NUM_FRAMES - 1:
        print(f"Rendered {i + 1}/{NUM_FRAMES} frames")

# Save to MP4
print(f"\nSaving video to {OUTPUT_FILENAME}...")
fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for MP4
out = cv2.VideoWriter(OUTPUT_FILENAME, fourcc, FPS, (ANIM_WIDTH, ANIM_HEIGHT))

for frame in frames:
    out.write(frame)

out.release()

# Verify and output path
if os.path.exists(OUTPUT_FILENAME):
    print(f"Video generated successfully: {os.path.abspath(OUTPUT_FILENAME)}")
else:
    print("Error: Video file was not created.")

```

## Configure High-Resolution Animation

### Subtask:
Define animation parameters for a higher resolution (e.g., 1000x750) and a suitable number of frames (e.g., 360) to ensure a smooth, looping 45-degree inclined orbit.

**Reasoning**:
Define the animation parameters, including resolution, frame count, FPS, output filename, and inclination angle, as specified in the instructions.
"""

import cv2

# Animation Parameters
ANIM_WIDTH = 1000
ANIM_HEIGHT = 750
NUM_FRAMES = 360  # For a smooth 360-degree loop
FPS = 24
OUTPUT_FILENAME = 'black_hole_inclined_orbit.mp4'
INCLINATION_ANGLE_DEG = 45.0 # Angle of the orbit relative to the disk plane

print(f"Animation Configuration (High-Resolution Inclined Orbit):")
print(f"Resolution: {ANIM_WIDTH}x{ANIM_HEIGHT}")
print(f"Frames: {NUM_FRAMES}")
print(f"FPS: {FPS}")
print(f"Output File: {OUTPUT_FILENAME}")
print(f"Inclination Angle: {INCLINATION_ANGLE_DEG} degrees")

"""**Reasoning**:
The animation parameters have been defined and verified in the previous step. Now, I will proceed to calculate the camera trajectory for the inclined orbit, render each frame using the `render_image` function, and then compile these frames into an MP4 video file, as per the main task's instructions.


"""

import numpy as np
import cv2
import os

# Animation Parameters for High-Resolution Inclined Orbit
ANIM_WIDTH = 1000
ANIM_HEIGHT = 750
NUM_FRAMES = 360  # For a smoother 360-degree loop
FPS = 24
OUTPUT_FILENAME = 'black_hole_inclined_orbit.mp4'
INCLINATION_ANGLE_DEG = 45.0 # Angle relative to the equatorial (XZ) plane

print(f"Animation Configuration for Inclined Orbit:")
print(f"Resolution: {ANIM_WIDTH}x{ANIM_HEIGHT}")
print(f"Frames: {NUM_FRAMES}")
print(f"FPS: {FPS}")
print(f"Inclination Angle: {INCLINATION_ANGLE_DEG} degrees")
print(f"Output File: {OUTPUT_FILENAME}")

# Trajectory and Rendering
print(f"\nStarting render of {NUM_FRAMES} frames for inclined orbit...")
frames = []

# Center of the black hole (camera target)
target = np.array([0.0, 0.0, 0.0])

inclination_rad = np.radians(INCLINATION_ANGLE_DEG)

for i in range(NUM_FRAMES):
    # Orbital angle for this frame (0 to 2pi)
    theta = (2.0 * np.pi * i) / NUM_FRAMES

    # Calculate camera position for a 45-degree inclined orbit
    # Assuming Y-axis is 'north-south' and XZ plane is 'equator'.
    # Start with an orbit in the XZ plane (equator) and rotate it around the X-axis
    # by the inclination angle.
    x = CAM_DIST * np.cos(theta)
    y = CAM_DIST * np.sin(theta) * np.sin(inclination_rad)
    z = CAM_DIST * np.sin(theta) * np.cos(inclination_rad)

    cam_pos_i = np.array([x, y, z])

    # Render frame
    # render_image, CAM_DIST, and FOV are defined in previous cells
    img_data = render_image(ANIM_WIDTH, ANIM_HEIGHT, cam_pos_i, target, FOV)

    # Convert to uint8 for OpenCV
    img_data = np.clip(img_data, 0.0, 1.0)
    img_uint8 = (img_data * 255).astype(np.uint8)

    # Convert RGB to BGR for OpenCV
    frame_bgr = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR)
    frames.append(frame_bgr)

    if (i + 1) % (NUM_FRAMES // 10) == 0 or i == 0 or i == NUM_FRAMES - 1:
        print(f"Rendered {i + 1}/{NUM_FRAMES} frames")

# Save to MP4
print(f"\nSaving video to {OUTPUT_FILENAME}...")
fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for MP4
out = cv2.VideoWriter(OUTPUT_FILENAME, fourcc, FPS, (ANIM_WIDTH, ANIM_HEIGHT))

for frame in frames:
    out.write(frame)

out.release()

# Verify and output path
if os.path.exists(OUTPUT_FILENAME):
    print(f"Video generated successfully: {os.path.abspath(OUTPUT_FILENAME)}")
else:
    print("Error: Video file was not created.")

"""# Task
Define the simulation constants (including `CAM_DIST`, `FOV`, `RS`, etc.) and import necessary libraries to ensure the environment is correctly configured. Create a directory named "frames" to store intermediate images. Implement a resumable rendering loop for a 360-frame, 45-degree inclined orbit: for each frame, check if the file (e.g., `frame_000.png`) already exists in the "frames" directory. If it exists, skip rendering; if not, calculate the camera position, render the image, and save it immediately. Once all frames are generated, compile them into a video file named "black_hole_inclined_orbit.mp4" and verify its existence by printing the absolute path.

## Configure Environment and Constants

### Subtask:
Import libraries, define simulation constants, and create the output directory for frames.

**Reasoning**:
I will import the necessary libraries and explicitly define the simulation and animation constants as requested. I will also create the 'frames' directory to ensure the output path exists for subsequent rendering steps.
"""

import numpy as np
import cv2
import os

# Simulation Constants
CAM_DIST = 30.0
FOV = 60.0
RS = 1.0

# Animation Configuration
ANIM_WIDTH = 1000
ANIM_HEIGHT = 750
NUM_FRAMES = 360
FPS = 24

# Output directory for frames
os.makedirs("frames", exist_ok=True)

print("Environment configured.")
print(f"Simulation: CAM_DIST={CAM_DIST}, FOV={FOV}, RS={RS}")
print(f"Animation: {ANIM_WIDTH}x{ANIM_HEIGHT}, {NUM_FRAMES} frames, {FPS} FPS")
print("Output directory 'frames' created.")

"""**Reasoning**:
I will implement the resumable rendering loop and video compilation as specified. This involves iterating through the frame indices, checking for existing files, rendering missing frames using the 45-degree inclined orbit trajectory, and then compiling all frames into an MP4 video file.


"""

import numpy as np
import cv2
import os

# Constants (Already defined, but ensuring scope availability)
INCLINATION_DEG = 45.0
OUTPUT_VIDEO = 'black_hole_inclined_orbit.mp4'

# Trajectory setup
inclination_rad = np.radians(INCLINATION_DEG)
target = np.array([0.0, 0.0, 0.0])

print(f"Starting generation of {NUM_FRAMES} frames...")

# 1. Rendering Loop (Resumable)
for i in range(NUM_FRAMES):
    filename = f"frames/frame_{i:03d}.png"

    if os.path.exists(filename):
        if i % 20 == 0:
            print(f"Frame {i}/{NUM_FRAMES} already exists. Skipping.")
        continue

    # Calculate Camera Position (Inclined Orbit)
    # Orbit in X-Z plane (equatorial) rotated by inclination around X-axis
    # Parametric circle: theta goes 0 -> 2pi
    theta = (2.0 * np.pi * i) / NUM_FRAMES

    # Base circle in XZ plane: x = R cos(t), z = R sin(t), y = 0
    # Rotate around X-axis by 'inclination':
    # y' = y*cos(inc) - z*sin(inc)  (Note: check rotation sign convention, usually y' = y c - z s)
    # z' = y*sin(inc) + z*cos(inc)
    # Let's use the explicit formula derived for the task:
    x = CAM_DIST * np.cos(theta)
    y = CAM_DIST * np.sin(theta) * np.sin(inclination_rad)
    z = CAM_DIST * np.sin(theta) * np.cos(inclination_rad)

    cam_pos = np.array([x, y, z])

    # Render Frame
    # Note: render_image returns an RGB float array (0.0 to 1.0)
    img_rgb = render_image(ANIM_WIDTH, ANIM_HEIGHT, cam_pos, target, FOV)

    # Convert to BGR uint8 for OpenCV
    img_rgb = np.clip(img_rgb, 0.0, 1.0)
    img_uint8 = (img_rgb * 255).astype(np.uint8)
    img_bgr = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR)

    # Save immediately
    cv2.imwrite(filename, img_bgr)

    if i % 5 == 0:
        print(f"Rendered and saved frame {i}/{NUM_FRAMES}")

print("Frame generation complete.")

# 2. Video Compilation
print(f"Compiling video to {OUTPUT_VIDEO}...")
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, FPS, (ANIM_WIDTH, ANIM_HEIGHT))

frames_processed = 0
for i in range(NUM_FRAMES):
    filename = f"frames/frame_{i:03d}.png"
    frame = cv2.imread(filename)

    if frame is None:
        print(f"Warning: Could not read {filename}. Skipping frame.")
        continue

    out.write(frame)
    frames_processed += 1

out.release()

if os.path.exists(OUTPUT_VIDEO):
    print(f"Video generated successfully: {os.path.abspath(OUTPUT_VIDEO)}")
    print(f"Total frames compiled: {frames_processed}")
else:
    print("Error: Video file was not created.")

"""**Reasoning**:
The error `NameError: name 'render_image' is not defined` indicates that the `render_image` function and its dependencies (Numba kernels) were not defined in the current session or were lost. I will redefine the necessary constants and JIT-compiled functions (`get_derivatives`, `rk4_step`, `texture_lookup`, `ray_march`, `render_image`) before executing the animation loop.


"""

import numpy as np
import cv2
import os
from numba import njit, prange

# ==========================================
# 1. RE-DEFINE PHYSICS KERNELS (Fix for NameError)
# ==========================================

RS = 1.0
R_ISCO = 3.0 * RS
R_DISK_MAX = 12.0 * RS
STEP_SIZE = 0.05
MAX_STEPS = 5000

@njit
def get_derivatives(state):
    r = state[0]
    r_dot = state[1]
    phi = state[2]
    phi_dot = state[3]
    phi_ddot = -2.0 / r * r_dot * phi_dot
    r_ddot = r * (phi_dot ** 2) * (1.0 - (1.5 * RS) / r)
    return np.array([r_dot, r_ddot, phi_dot, phi_ddot])

@njit
def rk4_step(state, h):
    k1 = get_derivatives(state)
    k2 = get_derivatives(state + 0.5 * h * k1)
    k3 = get_derivatives(state + 0.5 * h * k2)
    k4 = get_derivatives(state + h * k3)
    return state + (h / 6.0) * (k1 + 2*k2 + 2*k3 + k4)

@njit
def texture_lookup(r, phi, x_hit, y_hit, z_hit):
    ring_noise = 0.6 * np.sin(r * 2.0) + 0.4 * np.sin(r * 5.0)
    brightness = 0.6 + 0.4 * ring_noise
    doppler = 1.0 + 0.5 * (x_hit / r)
    dist_norm = (r - R_ISCO) / (R_DISK_MAX - R_ISCO)
    dist_norm = max(0.0, min(1.0, dist_norm))
    col_r = 1.0 * brightness * doppler
    col_g = (0.8 - 0.6 * dist_norm) * brightness * doppler
    col_b = (0.3 - 0.3 * dist_norm) * brightness * doppler
    return np.array([col_r, col_g, col_b])

@njit
def ray_march(ray_origin, ray_dir):
    pos = ray_origin
    vel = ray_dir
    L = np.cross(pos, vel)
    L_norm = np.linalg.norm(L)
    if L_norm < 1e-6: return np.array([0.0, 0.0, 0.0])

    r_hat = pos / np.linalg.norm(pos)
    n_hat = L / L_norm
    phi_hat = np.cross(n_hat, r_hat)
    r_init, phi_init = np.linalg.norm(pos), 0.0
    dr_init = np.dot(vel, r_hat)
    dphi_init = np.dot(vel, phi_hat) / r_init
    state = np.array([r_init, dr_init, phi_init, dphi_init])

    for i in range(MAX_STEPS):
        old_r, old_phi = state[0], state[2]
        state = rk4_step(state, STEP_SIZE)
        new_r, new_phi = state[0], state[2]

        if new_r < RS: return np.array([0.0, 0.0, 0.0])
        if new_r > 50.0: return np.array([0.02, 0.02, 0.05])

        pos_3d_new = new_r * (np.cos(new_phi) * r_hat + np.sin(new_phi) * phi_hat)
        pos_3d_old = old_r * (np.cos(old_phi) * r_hat + np.sin(old_phi) * phi_hat)
        y0, y1 = pos_3d_old[1], pos_3d_new[1]

        if (y0 > 0 and y1 < 0) or (y0 < 0 and y1 > 0):
            fraction = abs(y0) / (abs(y0) + abs(y1))
            hit_r = old_r + (new_r - old_r) * fraction
            if R_ISCO < hit_r < R_DISK_MAX:
                hit_pos = pos_3d_old + (pos_3d_new - pos_3d_old) * fraction
                return texture_lookup(hit_r, 0, hit_pos[0], hit_pos[1], hit_pos[2])
    return np.array([0.0, 0.0, 0.0])

@njit(parallel=True)
def render_image(width, height, cam_pos, cam_target, fov):
    image = np.zeros((height, width, 3))
    aspect_ratio = width / height
    fov_rad = np.radians(fov)
    half_height = np.tan(fov_rad / 2.0)
    half_width = aspect_ratio * half_height
    w = (cam_target - cam_pos); w = w / np.linalg.norm(w)
    up = np.array([0.0, 1.0, 0.0])
    u = np.cross(w, up); u = u / np.linalg.norm(u)
    v = np.cross(u, w)

    for y in prange(height):
        for x in prange(width):
            ndc_x = (x + 0.5) / width * 2.0 - 1.0
            ndc_y = 1.0 - (y + 0.5) / height * 2.0
            pixel_screen_pos = cam_pos + w + u * (ndc_x * half_width) + v * (ndc_y * half_height)
            ray_dir = pixel_screen_pos - cam_pos
            ray_dir = ray_dir / np.linalg.norm(ray_dir)
            image[y, x] = ray_march(cam_pos, ray_dir)
    return image

# ==========================================
# 2. EXECUTE ANIMATION TASK
# ==========================================

CAM_DIST, FOV = 30.0, 60.0
ANIM_WIDTH, ANIM_HEIGHT = 1000, 750
NUM_FRAMES, FPS = 360, 24
INCLINATION_DEG = 45.0
OUTPUT_VIDEO = 'black_hole_inclined_orbit.mp4'
os.makedirs("frames", exist_ok=True)

inclination_rad = np.radians(INCLINATION_DEG)
target = np.array([0.0, 0.0, 0.0])
print(f"Starting generation of {NUM_FRAMES} frames...")

for i in range(NUM_FRAMES):
    filename = f"frames/frame_{i:03d}.png"
    if os.path.exists(filename):
        if i % 20 == 0: print(f"Frame {i}/{NUM_FRAMES} already exists. Skipping.")
        continue

    theta = (2.0 * np.pi * i) / NUM_FRAMES
    x = CAM_DIST * np.cos(theta)
    y = CAM_DIST * np.sin(theta) * np.sin(inclination_rad)
    z = CAM_DIST * np.sin(theta) * np.cos(inclination_rad)
    cam_pos = np.array([x, y, z])

    img_rgb = render_image(ANIM_WIDTH, ANIM_HEIGHT, cam_pos, target, FOV)
    img_bgr = cv2.cvtColor((np.clip(img_rgb, 0, 1) * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)
    cv2.imwrite(filename, img_bgr)
    if i % 5 == 0: print(f"Rendered and saved frame {i}/{NUM_FRAMES}")

print("Frame generation complete. Compiling video...")
out = cv2.VideoWriter(OUTPUT_VIDEO, cv2.VideoWriter_fourcc(*'mp4v'), FPS, (ANIM_WIDTH, ANIM_HEIGHT))
frames_processed = 0
for i in range(NUM_FRAMES):
    frame = cv2.imread(f"frames/frame_{i:03d}.png")
    if frame is not None:
        out.write(frame)
        frames_processed += 1
out.release()

if os.path.exists(OUTPUT_VIDEO):
    print(f"Video generated successfully: {os.path.abspath(OUTPUT_VIDEO)}")
else:
    print("Error: Video file was not created.")